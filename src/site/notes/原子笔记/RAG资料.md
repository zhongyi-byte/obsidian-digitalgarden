---
{"dg-publish":true,"permalink":"/原子笔记/RAG资料/","dgPassFrontmatter":true,"noteIcon":"1","created":"2024-01-01T17:24:59.388+08:00","updated":"2024-01-01T23:00:34.336+08:00"}
---


### 基础应用
1. chatbot
对话机器人。例如将乔布斯的所有资料（演讲、访谈、文章）等都放进资料库，以此构建的chatbot就像与其本人对话一样。
2. 客服机器人
将产品的相关资料放入机器人，由该ai机器人对客户问题进行解答。


#### 工作流程
![Pasted image 20240101173112.png](/img/user/%E6%94%B6%E9%9B%86%E7%AE%B1/attachments/Pasted%20image%2020240101173112.png)
1. 用户提问
2. 根据问题从知识库中检索出相关资料
3. 将问题和相关资料一起扔给大模型
4. 大模型返回回答

### 如何搭建？
1. 使用prompt为LLM提供指令 
	`您是一个Knowledge Bot。接下来将给您一份知识库中提取的文档内容（标记为DOCUMENT）和一个相关的问题。请使用知识库中的信息回答问题。`
2. 为LLM提供特定的知识来源
3. 将所有内容整合在一起并提出问题
以上流程存在的问题：
如何从外部数据源中检索到相似语料？
1. 将语句进行embedding向量化
2. 存入向量数据库
3. 通过向量数据库找出相近向量，对应到原始语句，就是那些可能对回答问题有帮助的资料。
4. 创建索引。包括加载和分割两个步骤
	1. 加载: 从各种数据（新闻，书本，图片，视频等）来源获取数据，并转化为通用格式。
	2. 分割: 将文本分割成适合搜索的小块，对其进行embedding
	![Pasted image 20240101183125.png](/img/user/%E6%94%B6%E9%9B%86%E7%AE%B1/attachments/Pasted%20image%2020240101183125.png)

全流程：![Pasted image 20240101183217.png](/img/user/%E6%94%B6%E9%9B%86%E7%AE%B1/attachments/Pasted%20image%2020240101183217.png)
参考资料：[RAG技术详解：揭秘基于垂直领域专有数据的 Chatbots 是如何实现的](https://xie.infoq.cn/article/b2fd611fc9a60a183d157b456)

### 生产中存在的问题
清楚上述流程后，利用开源工具，很快就能搭建起一个问答机器人。但实践中可能碰到的一些问题：
1. 文档种类多。ppt、pdf中包含的图片如何解析，并与文字映射起来。
2. 切分方式。采用定长切分会导致每段文本包含的语义未必完整，同时丢失标题等关键信息
3. 内部知识的特殊性。训练语料用的是通用语料，而对于某个特定领域，存在很多专业术语，会影响生成向量的精确度。
4. 用户提问的随意性
解决方式:
1. 多模态模型+摘要描述
2. 文档元素的组织形式是树状，通过遍历文档树，可以渠道较为完整的语义段落和标题。
3. finetune Embedding向量模型，使得其能够理解垂直领域的场景
4. 增加追问机制，提供合适的问句给用户，使用户在多轮引导中明确自己的问题。

附带：
1. rag fusion技术，生成多个相似query，可以提高召回率
2. 解析存储。用于解决文本的特殊结构问题


参考资料：[对于大模型RAG技术的一些思考](https://zhuanlan.zhihu.com/p/670432927?utm_id=0)

---
## 生产调优策略

参考资料：[12 种调整策略指南：为生产环境打造高效的 RAG 应用 [译]](https://baoyu.io/translations/rag/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications#ingestion-stage)
### 数据录入阶段的调优策略
数据录入包括以下几个步骤：
1. 收集数据
2. 数据分割
3. 对分割后的数据进行embeddiing
4. 将embedding后的向量存入数据库

#### 数据清理
1. 清洁：基本的数据清理，确保所有特殊字符都被正确编码
2. 准确：确保信息是连贯且准确的
#### 文档分块
根据不同的数据类型，如html、markdown、代码块选择不同的分块策略（langchain中自带有不同的文本分割器）。
理想的分块长度因应用场景而异。如问答系统需要较精简的信息块，而内容摘要需要较长的信息块。

#### embeddiing模型选择
1. 模型选择。参考 [Massive Text Embedding Benchmark (MTEB) 排行榜](https://huggingface.co/spaces/mteb/leaderboard)，汇集了164种embedding模型的比较
2. 对模型进行finetune，以适应特定领域和场景。可以在检索效果提高5-10%
#### 元数据
一些向量数据库支持将向量与元数据一同存储，如日期、章节或引用等额外信息
#### 多重索引技术
针对不同文档类型采用不同的索引策略。需要在数据检索时加入索引路由机制。
附带： 原生多租户

#### 索引算法
向量索引有多种算法，在存储空间和索引速度、读取速度上进行了取舍。
[关于 RAG 评估的概述 | Weaviate - 向量数据库](https://weaviate.io/blog/rag-evaluation?source=post_page-----7ca646833439--------------------------------#indexing-knobs)

### 推理阶段（检索与生成）

#### 检索参数
* 语义检索or混合搜索（语义检索结合传统的基于关键词的搜索）
* 
* 检索结果的数量

#### 高级检索策略
推荐课程：[构建和评估高级 RAG 应用](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/?source=post_page-----7ca646833439--------------------------------)
核心理念：用于检索的数据块不必是生成内容的同一数据块。
语境增强
应该embedding更小的数据块，但是在检索时获取更广泛的上下文
* 窗口检索。查询时获取句子前后的相关句子![Pasted image 20240101225349.png](/img/user/%E6%94%B6%E9%9B%86%E7%AE%B1/attachments/Pasted%20image%2020240101225349.png)
* 自动合并检索。 在查询时，将若干个小的，相关数据块合并成一个更大的上下文。![Pasted image 20240101225359.png](/img/user/%E6%94%B6%E9%9B%86%E7%AE%B1/attachments/Pasted%20image%2020240101225359.png)
这个想法很好。值得深挖。
#### 重排序模型
>“最相似”不总意味着“最相关”

像[Cohere 的 Rerank](https://cohere.com/rerank?ref=txt.cohere.com&__hstc=14363112.8fc20f6b1a1ad8c0f80dcfed3741d271.1697800567394.1701091033915.1701173515537.7&__hssc=14363112.1.1701173515537&__hsfp=3638092843) 这样的**重排序模型**能够通过为每个检索结果计算与查询相关性的得分，帮助排除不相关的搜索结果
#### prompt
* 巧妙的设计提示词
* 加入少量（few-shot）示例